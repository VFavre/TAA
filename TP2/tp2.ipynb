{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Favre Victor et Badiel Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4375, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"credit_scoring.csv\",sep = ';')\n",
    "data_ar = data.to_numpy()\n",
    "print(np.shape(data_ar))\n",
    "\n",
    "positive = data_ar[data_ar[:,13] == 1]\n",
    "negative = data_ar[data_ar[:,13] == 0]\n",
    "\n",
    "plt.hist(data_ar[:,13], ec=\"k\")\n",
    "plt.xticks((0,1))\n",
    "plt.title(\"histogram\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_ar[:,:13]\n",
    "y = data_ar[:,13]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.52       604\n",
      "         1.0       0.82      0.80      0.81      1584\n",
      "\n",
      "    accuracy                           0.73      2188\n",
      "   macro avg       0.66      0.67      0.67      2188\n",
      "weighted avg       0.73      0.73      0.73      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNeighbors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.31      0.39       604\n",
      "         1.0       0.77      0.88      0.82      1584\n",
      "\n",
      "    accuracy                           0.72      2188\n",
      "   macro avg       0.64      0.60      0.60      2188\n",
      "weighted avg       0.70      0.72      0.70      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.47      0.41       604\n",
      "         1.0       0.77      0.68      0.73      1584\n",
      "\n",
      "    accuracy                           0.63      2188\n",
      "   macro avg       0.57      0.58      0.57      2188\n",
      "weighted avg       0.66      0.63      0.64      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(40,20),activation=\"relu\").fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compte tenu du principe du credit score il est plus intéressant de chercher a maximiser la precision du 1 que le reste.\n",
    "on remarque sur la précision que tout les algorithme sont similaire meme si le neural network est en tete avec 74% d'accuracy. Cependant si l'on regarde la precision sur 1 le deicison tree est dans ce cas ben meilleur que les autre etant donné qu'il atteint 82% de precision compraré aux autre qui atteigne 75 ou 77 %"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# normalisation et standardisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train_standar = sc_X.fit_transform(X_train)\n",
    "X_test_standar = sc_X.transform(X_test)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_test_minmax = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.53      0.52       604\n",
      "         1.0       0.82      0.80      0.81      1584\n",
      "\n",
      "    accuracy                           0.73      2188\n",
      "   macro avg       0.66      0.67      0.66      2188\n",
      "weighted avg       0.73      0.73      0.73      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train_standar,y_train)\n",
    "y_pred = clf.predict(X_test_standar)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.52       604\n",
      "         1.0       0.82      0.80      0.81      1584\n",
      "\n",
      "    accuracy                           0.73      2188\n",
      "   macro avg       0.66      0.67      0.67      2188\n",
      "weighted avg       0.73      0.73      0.73      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train_minmax,y_train)\n",
    "y_pred = clf.predict(X_test_minmax)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.47      0.51       604\n",
      "         1.0       0.81      0.86      0.83      1584\n",
      "\n",
      "    accuracy                           0.75      2188\n",
      "   macro avg       0.69      0.67      0.67      2188\n",
      "weighted avg       0.74      0.75      0.75      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train_standar, y_train)\n",
    "y_pred = neigh.predict(X_test_standar)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.52       604\n",
      "         1.0       0.82      0.80      0.81      1584\n",
      "\n",
      "    accuracy                           0.73      2188\n",
      "   macro avg       0.66      0.67      0.67      2188\n",
      "weighted avg       0.73      0.73      0.73      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test_minmax)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.57      0.59       604\n",
      "         1.0       0.84      0.86      0.85      1584\n",
      "\n",
      "    accuracy                           0.78      2188\n",
      "   macro avg       0.73      0.72      0.72      2188\n",
      "weighted avg       0.78      0.78      0.78      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(40,20),activation=\"relu\")\n",
    "mlp.fit(X_train_standar, y_train)\n",
    "y_pred = mlp.predict(X_test_standar)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.54      0.60       604\n",
      "         1.0       0.84      0.89      0.86      1584\n",
      "\n",
      "    accuracy                           0.80      2188\n",
      "   macro avg       0.75      0.72      0.73      2188\n",
      "weighted avg       0.79      0.80      0.79      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train_minmax, y_train)\n",
    "y_pred = mlp.predict(X_test_minmax)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suite a la normalisation ou la standardisation on remarque une forte augmentation des réusulats pour le neural network de l'odre de de 7 a 9 % pour la précision est de 2 a 3 % d'accuracy. Quand aux autre algorithmes le decision tree n'est pas impacté par la normalisation et la KN quand a lui gagne 5 % de precision. On peux aussi remarquer des differences sur les résultat en fonction de si la standarsisation ou la normalisation est utilisé ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca_train = pca.fit_transform(X_train_standar)\n",
    "X_train_pca = np.concatenate([X_train_standar,pca_train[:,:3]], axis = 1)\n",
    "pca_test = pca.transform(X_test_standar)\n",
    "X_test_pca = np.concatenate([X_test_standar,pca_test[:,:3]], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.58      0.55       604\n",
      "         1.0       0.83      0.80      0.81      1584\n",
      "\n",
      "    accuracy                           0.74      2188\n",
      "   macro avg       0.68      0.69      0.68      2188\n",
      "weighted avg       0.75      0.74      0.74      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.47      0.52       604\n",
      "         1.0       0.81      0.87      0.84      1584\n",
      "\n",
      "    accuracy                           0.76      2188\n",
      "   macro avg       0.69      0.67      0.68      2188\n",
      "weighted avg       0.74      0.76      0.75      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh.fit(X_train_pca, y_train)\n",
    "y_pred = neigh.predict(X_test_pca)\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.50      0.54       604\n",
      "         1.0       0.82      0.87      0.84      1584\n",
      "\n",
      "    accuracy                           0.77      2188\n",
      "   macro avg       0.71      0.69      0.69      2188\n",
      "weighted avg       0.76      0.77      0.76      2188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(40,20),activation=\"relu\")\n",
    "mlp.fit(X_train_pca, y_train)\n",
    "y_pred = mlp.predict(X_test_pca)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suite a la PCA on remarque que l'impact général est res faible et n'entraine une augmentation de precision et d'accuracy de l'odre de 1% et entraine meme une perte de 1% de precision pour certain algothime comme le Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sélection de variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Income', 'Seniority', 'Price', 'Amount', 'Age', 'Assets', 'Expenses',\n",
      "       'Records', 'Time', 'Job', 'Debt', 'Home', 'Marital'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_standar,y_train)\n",
    "importances=clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "nom_cols = data.columns\n",
    "features = nom_cols #see if it's well organized\n",
    "print(features[sorted_idx])\n",
    "padding = np.arange(X_train_standar.size/len(X_train_standar)) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center')\n",
    "plt.yticks(padding, features[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "scores=np.zeros(X_train_standar.shape[1]+1)\n",
    "for f in np.arange(0, X_train_standar.shape[1]+1):\n",
    "    X1_f = X_train_standar[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test_standar[:,sorted_idx[:f+1]]\n",
    "    KNN.fit(X1_f,y_train)\n",
    "    YKNN=KNN.predict(X2_f)\n",
    "    scores[f]=np.round(metrics.accuracy_score(y_test,YKNN),3)\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suite au graph précedent on peut conclure que la nombre optimale de variable est de 7 car l'ajout de variable entraien ou une perte d'accuracy de l'odre de 0.01 ou aucune amélioration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "retest with only the 7 best features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "X_train_best = X_train_standar[:,sorted_idx[:7]]\n",
    "X_test_best = X_test_standar[:,sorted_idx[:7]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GridSearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision tree grid search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 4, 'min_samples_leaf': 1}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'max_depth':[2,3,4,5,6,7],\n",
    "    'min_samples_leaf' : [1,2,3]\n",
    "}\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "'''\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "'''\n",
    "clf = GridSearchCV(clf, parameters, scoring='accuracy',cv=10, verbose=False)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "scoring = clf.cv_results_\n",
    "clf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### grid search KN neighbours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'algorithm': 'ball_tree', 'leaf_size': 1, 'n_neighbors': 9, 'p': 2}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_neighbors':[2,3,4,5,6,7,8,9,10],\n",
    "    'leaf_size' : [1,2,3,4,5,10,30,40],\n",
    "    'p':[1,2],\n",
    "    'algorithm':['ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "neigh = KNeighborsClassifier()\n",
    "'''\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "'''\n",
    "clf = GridSearchCV(neigh, parameters, scoring='accuracy',cv=10, verbose=False)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "scoring = clf.cv_results_\n",
    "clf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GridSearch multi layer perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'activation': 'identity', 'alpha': 0.001, 'hidden_layer_sizes': (60, 40)}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parameters = {\n",
    "    'activation' : [\"identity\",\"logistic\",\"tanh\",\"relu\"],\n",
    "    'hidden_layer_sizes':[(80,40),(50,15),(60,40),(60,30)],\n",
    "    'alpha':[0.001,0.00005,0.0001,0.0005]\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(random_state = 1,solver = 'adam',learning_rate = \"adaptive\")\n",
    "'''\n",
    "mlp.fit(X_train_pca, y_train)\n",
    "y_pred = mlp.predict(X_test_pca)\n",
    "'''\n",
    "clf = GridSearchCV(mlp, parameters, scoring='accuracy',cv=10, verbose=False)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "scoring = clf.cv_results_\n",
    "clf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pickle\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler),\n",
    "    ('pca', PCA(n_components = 3)),\n",
    "    ('tree', tree.DecisionTreeClassifier(random_state=1, max_depth= 4, min_samples_leaf= 1))\n",
    "])\n",
    "\n",
    "with open('pipeline.pickle', 'wb') as handle:\n",
    "    pickle.dump(pipe, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# or if we can use joblib\n",
    "#import joblib\n",
    "#from sklearn.externals import joblib\n",
    "#joblib.dump(pipeline, 'pipeline.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparaison d'algorithmes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.805 +/- 0.033 roc is: 0.757 +/- 0.038\n",
      "Accuracy for KNN is: 0.796 +/- 0.032 roc is: 0.766 +/- 0.018\n",
      "Accuracy for Bayes is: 0.820 +/- 0.032 roc is: 0.773 +/- 0.033\n",
      "Accuracy for CART is: 0.804 +/- 0.030 roc is: 0.646 +/- 0.028\n",
      "Accuracy for ID30 is: 0.790 +/- 0.036 roc is: 0.627 +/- 0.032\n",
      "Accuracy for MLP is: 0.834 +/- 0.029 roc is: 0.834 +/- 0.019\n",
      "Accuracy for neihgbors is: 0.797 +/- 0.032 roc is: 0.741 +/- 0.019\n",
      "Accuracy for bagging is: 0.808 +/- 0.030 roc is: 0.792 +/- 0.024\n",
      "Accuracy for ADA is: 0.815 +/- 0.029 roc is: 0.818 +/- 0.029\n",
      "Accuracy for RNDForest is: 0.778 +/- 0.034 roc is: 0.818 +/- 0.022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs = {\n",
    "    'TREE': tree.DecisionTreeClassifier(max_depth= 4, min_samples_leaf= 1, random_state=1),\n",
    "    'KNN': KNeighborsClassifier(algorithm= 'ball_tree', leaf_size= 1, n_neighbors= 9, p= 2),\n",
    "    'Bayes': GaussianNB(),\n",
    "    'CART': tree.DecisionTreeClassifier(random_state=1),\n",
    "    'ID30': tree.DecisionTreeClassifier(random_state=1,criterion = \"entropy\"),\n",
    "    'MLP': MLPClassifier(random_state = 1,solver = 'adam',learning_rate = \"adaptive\"),\n",
    "    'neihgbors':KNeighborsClassifier(),\n",
    "    'bagging':BaggingClassifier(n_estimators=50, random_state=1),\n",
    "    'ADA': AdaBoostClassifier(n_estimators=50, random_state=0),\n",
    "    'RNDForest':RandomForestClassifier(n_estimators=50, max_depth=5, random_state=1)\n",
    "}\n",
    "def run_classifiers(_clfs, _X, _y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for i in _clfs:\n",
    "        clf = _clfs[i]\n",
    "        cv_acc = cross_val_score(clf, _X, _y, cv=kf, scoring= \"precision\")\n",
    "        auc = cross_val_score(clf, _X, _y, cv=kf, scoring= 'roc_auc')\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f} roc is: {3:.3f} +/- {4:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc), np.mean(auc), np.std(auc)))\n",
    "\n",
    "run_classifiers(clfs,X_train_pca,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "sur l'enssemble des algothimes testés on peux remarqué que ceux ci performe en générale de manière tout a fait convenable ceux ci étant tous autour de 80% de précision. On peux tout de meme remarqué que parmis tous celui ayant obtenu la meilleur précision est le Neural Network qui obtient la meilleur précision et roc score. Le second meilleur est Bayes qui arrive a etre meilleur que les 2 autres algothimes que nous avons tuner. Il pourai donc etre interessant de changer les hypermaramètre de celui pour voir qu'elle résultats peuvent etre obtenue"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Données hétérogènes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0      1       2  3  4   5   6     7  8  9   10 11 12   13   14 15\n",
      "0    b  30.83   0.000  u  g   w   v  1.25  t  t   1  f  g  202    0  +\n",
      "1    a  58.67   4.460  u  g   q   h  3.04  t  t   6  f  g   43  560  +\n",
      "2    a  24.50   0.500  u  g   q   h  1.50  t  f   0  f  g  280  824  +\n",
      "3    b  27.83   1.540  u  g   w   v  3.75  t  t   5  t  g  100    3  +\n",
      "4    b  20.17   5.625  u  g   w   v  1.71  t  f   0  f  s  120    0  +\n",
      "..  ..    ...     ... .. ..  ..  ..   ... .. ..  .. .. ..  ...  ... ..\n",
      "683  b  21.08  10.085  y  p   e   h  1.25  f  f   0  f  g  260    0  -\n",
      "684  a  22.67   0.750  u  g   c   v  2.00  f  t   2  t  g  200  394  -\n",
      "685  a  25.25  13.500  y  p  ff  ff  2.00  f  t   1  t  g  200    1  -\n",
      "686  b  17.92   0.205  u  g  aa   v  0.04  f  f   0  f  g  280  750  -\n",
      "687  b  35.00   3.375  u  g   c   h  8.29  f  f   0  t  g    0    0  -\n",
      "\n",
      "[688 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_data = pd.read_csv(\"credit.data\", sep = '\\t', header = None)\n",
    "print(credit_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(688, 16)\n"
     ]
    }
   ],
   "source": [
    "data_ar = credit_data.to_numpy()\n",
    "print(np.shape(data_ar))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "credit_data.replace('+', 1, inplace=True)\n",
    "credit_data.replace('-', 0, inplace=True)\n",
    "credit_data[1].replace('?', np.nan, inplace=True)\n",
    "credit_data[1] = credit_data[1].astype(float) #désolé on avait plus le temps\n",
    "credit_data[13].replace('?', np.nan, inplace=True)\n",
    "credit_data[13] = credit_data[1].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il y a en tout 305 cas positif\n",
      "il y a en tout 383 cas negatif\n"
     ]
    }
   ],
   "source": [
    "number = credit_data.select_dtypes(include='number')\n",
    "number = number.iloc[: , :-1]\n",
    "number = number.astype(float)\n",
    "number.dropna(axis = 0, inplace=True)\n",
    "number.replace('?',np.nan, inplace=True)\n",
    "number.dropna(inplace=True)\n",
    "\n",
    "print(\"il y a en tout\",credit_data[credit_data.iloc[:,-1] == 1].shape[0],\"cas positif\")\n",
    "print(\"il y a en tout\",credit_data[credit_data.iloc[:,-1] == 0].shape[0],\"cas negatif\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "X = credit_data.iloc[:,:15]\n",
    "y = credit_data.iloc[:,15]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.797 +/- 0.095 roc is: 0.812 +/- 0.046\n",
      "Accuracy for KNN is: 0.732 +/- 0.075 roc is: 0.759 +/- 0.058\n",
      "Accuracy for Bayes is: 0.835 +/- 0.088 roc is: 0.804 +/- 0.062\n",
      "Accuracy for CART is: 0.643 +/- 0.080 roc is: 0.681 +/- 0.057\n",
      "Accuracy for ID30 is: 0.676 +/- 0.073 roc is: 0.703 +/- 0.052\n",
      "Accuracy for MLP is: 0.712 +/- 0.115 roc is: 0.776 +/- 0.068\n",
      "Accuracy for neihgbors is: 0.723 +/- 0.100 roc is: 0.736 +/- 0.044\n",
      "Accuracy for bagging is: 0.756 +/- 0.057 roc is: 0.810 +/- 0.039\n",
      "Accuracy for ADA is: 0.796 +/- 0.057 roc is: 0.842 +/- 0.048\n",
      "Accuracy for RNDForest is: 0.819 +/- 0.067 roc is: 0.851 +/- 0.039\n"
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs,number.to_numpy(),y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque qu'une partie de nos algorthimes on eu une perte de précision engendré par le fait de prédire seulement sur les valeurs numérique."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_standar = sc_X.fit_transform(number)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_minmax = scaler.fit_transform(number)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.797 +/- 0.095 roc is: 0.812 +/- 0.046\n",
      "Accuracy for KNN is: 0.768 +/- 0.083 roc is: 0.795 +/- 0.061\n",
      "Accuracy for Bayes is: 0.835 +/- 0.088 roc is: 0.804 +/- 0.062\n",
      "Accuracy for CART is: 0.645 +/- 0.081 roc is: 0.682 +/- 0.057\n",
      "Accuracy for ID30 is: 0.675 +/- 0.075 roc is: 0.703 +/- 0.052\n",
      "Accuracy for MLP is: 0.816 +/- 0.084 roc is: 0.831 +/- 0.058\n",
      "Accuracy for neihgbors is: 0.755 +/- 0.089 roc is: 0.765 +/- 0.065\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-251-84aa1ce3b7c9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mrun_classifiers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclfs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mX_standar\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-97-f493355d547f>\u001B[0m in \u001B[0;36mrun_classifiers\u001B[1;34m(_clfs, _X, _y)\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_clfs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mcv_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_val_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m\"precision\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0mauc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_val_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'roc_auc'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Accuracy for {0} is: {1:.3f} +/- {2:.3f} roc is: {3:.3f} +/- {4:.3f}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mauc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mauc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    438\u001B[0m     \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_scorer\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mMake\u001B[0m \u001B[0ma\u001B[0m \u001B[0mscorer\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0ma\u001B[0m \u001B[0mperformance\u001B[0m \u001B[0mmetric\u001B[0m \u001B[1;32mor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    439\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 440\u001B[1;33m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    441\u001B[0m     \"\"\"\n\u001B[0;32m    442\u001B[0m     \u001B[1;31m# To ensure multimetric format is not supported\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[0mscorers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_multimetric_scoring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 246\u001B[1;33m     \u001B[1;31m# We clone the estimator to make sure that all the folds are\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    247\u001B[0m     \u001B[1;31m# independent, and that it is pickle-able.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    248\u001B[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1044\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1045\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_safe_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    594\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0my_train\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    242\u001B[0m         \u001B[0mself\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    243\u001B[0m         \"\"\"\n\u001B[1;32m--> 244\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_samples\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    245\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    246\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001B[0m\n\u001B[0;32m    368\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_seeds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mseeds\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 370\u001B[1;33m         all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001B[0m\u001B[0;32m    371\u001B[0m                                \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_parallel_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m             delayed(_parallel_build_estimators)(\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1040\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1041\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_parallel_build_estimators\u001B[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[1;31m# Draw random feature, sample indices\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m         features, indices = _generate_bagging_indices(random_state,\n\u001B[0m\u001B[0;32m     92\u001B[0m                                                       \u001B[0mbootstrap_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m                                                       \u001B[0mbootstrap\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_generate_bagging_indices\u001B[1;34m(random_state, bootstrap_features, bootstrap_samples, n_features, n_samples, max_features, max_samples)\u001B[0m\n\u001B[0;32m     55\u001B[0m     feature_indices = _generate_indices(random_state, bootstrap_features,\n\u001B[0;32m     56\u001B[0m                                         n_features, max_features)\n\u001B[1;32m---> 57\u001B[1;33m     sample_indices = _generate_indices(random_state, bootstrap_samples,\n\u001B[0m\u001B[0;32m     58\u001B[0m                                        n_samples, max_samples)\n\u001B[0;32m     59\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001B[0m in \u001B[0;36m_generate_indices\u001B[1;34m(random_state, bootstrap, n_population, n_samples)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;31m# Draw sample indices\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mbootstrap\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 39\u001B[1;33m         \u001B[0mindices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_population\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     40\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m         indices = sample_without_replacement(n_population, n_samples,\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs,X_standar,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_classifiers(clfs,X_minmax,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque que comme prédcédement la normalisation et la standardisation permet seulement a une partie des algorthimes (Neural network,bayes ...) d'obtenir un gain de précision et de ROC."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "col_num = credit_data.select_dtypes(include='number').columns\n",
    "col_num = col_num[:-1]\n",
    "col_cat = credit_data[credit_data.columns.difference(col_num)].columns\n",
    "col_cat = col_cat[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 7, 10, 13, 14], dtype='int64')\n",
      "Int64Index([0, 3, 4, 5, 6, 8, 9, 11, 12], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(col_num)\n",
    "print(col_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b' 'u' 'g' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'r' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'k' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 'f' 'f' 's']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'e' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'x' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'q' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'bb' 't' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'd' 'bb' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'm' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 'f' 's']\n",
      " ['a' 'u' 'g' 'd' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'd' 'v' 't' 'f' 't' 's']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'j' 'j' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 'f' 't' 's']\n",
      " ['a' 'y' 'p' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'bb' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'i' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'z' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 'f' 'f' 's']\n",
      " ['a' 'y' 'p' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'x' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'e' 'z' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'e' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'j' 'ff' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'bb' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'j' 'j' 't' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'e' 'z' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'm' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'e' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 't' 's']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 't' 'f' 's']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'i' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 't' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'e' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'z' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'x' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['?' 'u' 'g' 'c' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'e' 'z' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'h' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'o' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'x' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'e' 'dd' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'n' 'f' 'f' 'f' 'g']\n",
      " ['b' '?' '?' '?' '?' 'f' 'f' 'f' 'p']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'h' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'q' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'c' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 's']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'h' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'j' 'j' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 'f' 't' 's']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 's']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'h' 'f' 'f' 't' 's']\n",
      " ['a' 'y' 'p' 'j' 'j' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 't' 's']\n",
      " ['b' 'y' 'p' 'c' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'l' 'gg' 'ff' 'o' 'f' 'f' 't' 'p']\n",
      " ['b' 'y' 'p' 'm' 'bb' 'f' 'f' 't' 's']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'l' 'gg' 'cc' 'ff' 'f' 'f' 't' 's']\n",
      " ['a' 'u' 'g' 'cc' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'x' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['?' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'w' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'i' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' '?' '?' '?' '?' 'f' 'f' 'f' 'p']\n",
      " ['a' 'y' 'p' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'i' 'h' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'z' 'f' 'f' 'f' 'g']\n",
      " ['?' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'j' 'j' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'k' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'e' 'dd' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 'f' 's']\n",
      " ['a' 'y' 'p' 'k' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'r' 'n' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'dd' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'h' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['?' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'e' 'dd' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'e' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'x' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'j' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 's']\n",
      " ['a' 'y' 'p' 'k' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'p']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 't' 's']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 't' 'f' 's']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'j' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 'g']\n",
      " ['?' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' '?' '?' '?' '?' 'f' 'f' 'f' 'p']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'j' 'j' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'm' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'w' 'h' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'h' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'i' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'i' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'h' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'i' 'h' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 'f' 'g']\n",
      " ['?' 'y' 'p' '?' '?' 'f' 'f' 'f' 's']\n",
      " ['a' 'u' 'g' 'i' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 'f' 't' 'g']\n",
      " ['?' 'u' 'g' 'q' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'x' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'j' 'j' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'e' 'dd' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['?' 'u' 'g' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'e' 'dd' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'bb' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'bb' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' '?' '?' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'i' 'bb' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 'f' 's']\n",
      " ['b' 'u' 'g' 'e' 'z' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'r' 'n' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['a' 'y' 'p' 'x' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'cc' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'q' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'h' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'x' 'h' 't' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'h' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'e' 'v' 'f' 't' 'f' 's']\n",
      " ['b' 'u' 'g' 'm' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'h' 't' 'f' 't' 'g']\n",
      " ['a' 'y' 'p' 'e' 'z' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'h' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'y' 'p' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 't' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 't' 't' 'g']\n",
      " ['b' '?' '?' '?' '?' 'f' 'f' 'f' 'p']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 't' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 't' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 't' 't' 'f' 'g']\n",
      " ['?' 'u' 'g' 'q' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 't' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'k' 'v' 't' 't' 'f' 'g']\n",
      " ['?' 'y' 'p' '?' '?' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 't' 'f' 'f' 'g']\n",
      " ['a' 'y' 'p' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'x' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'q' 'h' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'bb' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 't' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'j' 'f' 'f' 't' 's']\n",
      " ['a' '?' '?' '?' '?' 'f' 'f' 'f' 'p']\n",
      " ['b' 'u' 'g' 'q' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'd' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'm' 'h' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'k' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'c' 'n' 'f' 't' 't' 'g']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 't' 'g']\n",
      " ['?' 'y' 'p' 'cc' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'u' 'g' 'k' 'h' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 't' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'bb' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'i' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'u' 'g' 'i' 'v' 't' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'q' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 'f' 't' 't' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'w' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'cc' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'w' 'v' 'f' 'f' 'f' 's']\n",
      " ['b' 'y' 'p' 'm' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 't' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'd' 'h' 'f' 'f' 't' 's']\n",
      " ['b' 'y' 'p' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'w' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'cc' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 'f' 't' 'g']\n",
      " ['?' 'y' 'p' 'e' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'i' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'q' 'h' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 't' 'f' 'g']\n",
      " ['a' 'u' 'g' 'ff' 'ff' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'k' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'y' 'p' 'd' 'h' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'i' 'v' 'f' 'f' 't' 'g']\n",
      " ['b' 'y' 'p' 'd' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'm' 'v' 'f' 'f' 't' 's']\n",
      " ['b' 'y' 'p' 'e' 'h' 'f' 'f' 'f' 'g']\n",
      " ['a' 'u' 'g' 'c' 'v' 'f' 't' 't' 'g']\n",
      " ['a' 'y' 'p' 'ff' 'ff' 'f' 't' 't' 'g']\n",
      " ['b' 'u' 'g' 'aa' 'v' 'f' 'f' 'f' 'g']\n",
      " ['b' 'u' 'g' 'c' 'h' 'f' 'f' 't' 'g']]\n"
     ]
    }
   ],
   "source": [
    "X_cat = credit_data.loc[:,col_cat].to_numpy()\n",
    "print(X_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "X_cat = np.copy(credit_data.loc[:,col_cat].to_numpy())\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "imp_cat = Imputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 13 8 1 1 0 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 11 4 1 0 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [2 2 1 13 8 1 0 0 2]\n",
      " [2 2 1 10 8 1 0 1 0]\n",
      " [2 2 1 12 4 1 0 1 0]\n",
      " [1 2 1 3 8 1 0 0 0]\n",
      " [2 3 3 9 4 1 0 0 0]\n",
      " [2 3 3 13 8 1 0 1 0]\n",
      " [2 2 1 2 4 0 0 1 0]\n",
      " [2 2 1 2 4 1 0 0 0]\n",
      " [1 2 1 9 8 1 0 1 0]\n",
      " [2 2 1 9 8 0 0 0 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [2 3 3 9 8 1 1 1 0]\n",
      " [2 2 1 10 8 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 4 4 1 0 1 0]\n",
      " [1 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 2 8 1 0 0 2]\n",
      " [1 2 1 2 8 1 1 1 0]\n",
      " [1 2 1 14 4 1 1 0 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [1 2 1 2 4 1 1 0 0]\n",
      " [1 2 1 7 1 1 1 1 0]\n",
      " [2 2 1 4 1 1 1 1 0]\n",
      " [2 2 1 5 4 1 1 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [2 2 1 1 8 1 1 1 0]\n",
      " [2 2 1 14 4 1 1 0 0]\n",
      " [2 2 1 7 1 1 1 1 0]\n",
      " [1 2 1 5 8 1 0 1 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [2 2 1 3 4 1 1 1 0]\n",
      " [1 2 1 14 4 1 1 1 0]\n",
      " [2 3 3 3 8 1 1 0 0]\n",
      " [2 2 1 6 3 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 2 4 1 1 0 0]\n",
      " [2 2 1 13 4 1 1 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [2 3 3 2 8 1 1 0 0]\n",
      " [2 2 1 2 4 1 1 1 0]\n",
      " [1 3 3 11 4 1 1 1 0]\n",
      " [2 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 7 1 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 2 4 1 0 1 0]\n",
      " [2 2 1 11 8 1 0 1 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [2 2 1 3 4 1 0 1 0]\n",
      " [2 3 3 13 8 1 0 1 0]\n",
      " [2 2 1 3 8 1 0 0 0]\n",
      " [2 2 1 7 4 1 0 1 0]\n",
      " [2 2 1 14 4 0 0 1 2]\n",
      " [2 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 1 0]\n",
      " [2 2 1 4 8 1 1 0 0]\n",
      " [1 3 3 11 8 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 3 8 1 1 1 0]\n",
      " [2 2 1 3 8 1 1 1 0]\n",
      " [1 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 0 0]\n",
      " [2 2 1 13 4 1 1 0 0]\n",
      " [2 2 1 14 4 1 1 1 0]\n",
      " [2 2 1 5 1 1 0 1 2]\n",
      " [2 2 1 4 1 1 0 1 0]\n",
      " [1 2 1 3 8 1 0 1 0]\n",
      " [2 2 1 10 8 1 0 0 2]\n",
      " [2 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 1 8 1 0 1 0]\n",
      " [1 3 3 1 8 1 0 1 0]\n",
      " [2 3 3 9 8 1 1 0 0]\n",
      " [2 2 1 2 8 1 0 0 0]\n",
      " [2 2 1 6 3 1 1 0 0]\n",
      " [1 2 1 10 8 1 0 0 2]\n",
      " [2 2 1 10 8 1 0 0 2]\n",
      " [1 2 1 4 8 1 0 1 0]\n",
      " [2 2 1 1 8 1 0 1 0]\n",
      " [2 2 1 2 1 1 0 1 2]\n",
      " [2 2 1 4 8 1 0 1 2]\n",
      " [2 3 3 1 8 1 0 0 0]\n",
      " [2 2 1 1 8 1 0 1 0]\n",
      " [1 2 1 8 5 1 0 1 0]\n",
      " [2 3 3 2 4 1 0 0 0]\n",
      " [2 2 1 2 8 1 0 0 0]\n",
      " [2 3 3 1 8 1 0 0 0]\n",
      " [2 3 3 2 4 1 0 1 0]\n",
      " [2 3 3 2 8 1 0 1 0]\n",
      " [1 2 1 7 1 1 0 1 0]\n",
      " [2 3 3 1 8 1 0 0 0]\n",
      " [2 2 1 2 1 1 0 1 2]\n",
      " [1 3 3 11 8 1 0 1 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [2 3 3 2 1 1 0 1 0]\n",
      " [2 3 3 2 8 1 0 0 0]\n",
      " [2 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 9 8 1 1 1 0]\n",
      " [2 3 3 7 4 1 1 1 0]\n",
      " [2 2 1 5 9 1 1 0 0]\n",
      " [2 2 1 9 8 1 0 0 2]\n",
      " [1 3 3 1 8 1 0 0 0]\n",
      " [2 3 3 14 4 1 0 1 0]\n",
      " [1 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [1 3 3 6 3 1 1 0 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [1 2 1 9 1 1 1 1 0]\n",
      " [2 3 3 2 4 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 11 4 1 1 1 0]\n",
      " [2 2 1 9 8 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 1 0]\n",
      " [1 2 1 3 4 1 1 1 0]\n",
      " [2 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 3 8 1 1 1 0]\n",
      " [1 2 1 1 8 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [2 2 1 14 4 1 1 1 0]\n",
      " [2 2 1 10 1 1 1 1 0]\n",
      " [2 2 1 11 8 1 1 1 0]\n",
      " [2 2 1 7 1 1 1 0 0]\n",
      " [1 2 1 13 8 1 0 0 2]\n",
      " [2 2 1 5 9 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [1 2 1 5 1 1 1 0 0]\n",
      " [2 2 1 2 1 1 1 0 0]\n",
      " [2 2 1 11 4 1 1 1 0]\n",
      " [2 2 1 11 4 1 0 1 0]\n",
      " [2 3 3 1 8 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 0 0]\n",
      " [1 2 1 13 8 1 1 1 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 3 4 1 1 1 0]\n",
      " [1 2 1 8 3 1 1 0 0]\n",
      " [2 3 3 3 4 1 1 0 0]\n",
      " [2 2 1 13 8 1 1 0 0]\n",
      " [2 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 11 8 1 1 1 0]\n",
      " [1 3 3 11 4 1 1 0 0]\n",
      " [1 2 1 2 1 1 1 1 0]\n",
      " [1 2 1 2 8 1 1 0 0]\n",
      " [1 2 1 3 4 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 10 4 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 3 4 1 1 1 0]\n",
      " [1 3 3 8 5 1 1 1 0]\n",
      " [1 3 3 14 4 1 1 0 0]\n",
      " [1 2 1 5 9 1 1 0 0]\n",
      " [2 2 1 9 4 1 1 1 0]\n",
      " [2 3 3 10 1 1 1 1 0]\n",
      " [2 2 1 14 4 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 1 0]\n",
      " [2 2 1 14 8 1 1 1 0]\n",
      " [2 3 3 5 4 1 0 1 0]\n",
      " [1 2 1 11 8 1 0 1 0]\n",
      " [1 2 1 11 4 1 0 0 0]\n",
      " [2 2 1 11 8 1 0 1 0]\n",
      " [1 2 1 3 8 1 0 0 0]\n",
      " [2 2 1 11 4 1 0 1 0]\n",
      " [2 3 3 4 8 0 0 1 0]\n",
      " [1 3 3 1 8 1 0 1 0]\n",
      " [2 2 1 2 1 1 0 0 0]\n",
      " [2 2 1 9 4 1 0 1 0]\n",
      " [1 2 1 9 4 1 0 1 0]\n",
      " [2 2 1 11 4 1 0 0 0]\n",
      " [2 3 3 13 8 1 0 1 0]\n",
      " [2 2 1 1 8 1 0 1 2]\n",
      " [1 2 1 1 8 1 0 0 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 1 8 1 1 0 0]\n",
      " [2 2 1 2 1 1 1 0 0]\n",
      " [1 2 1 7 1 1 1 0 2]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [1 2 1 2 8 1 1 0 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 2 4 1 1 0 0]\n",
      " [2 2 1 1 1 1 1 0 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [1 2 1 2 8 1 1 1 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 2 8 1 0 1 0]\n",
      " [2 2 1 7 4 1 0 0 0]\n",
      " [2 2 1 14 8 1 0 0 0]\n",
      " [2 3 3 13 8 1 1 0 0]\n",
      " [2 3 3 7 1 1 1 1 0]\n",
      " [2 3 3 2 1 1 1 1 0]\n",
      " [2 3 3 14 8 1 1 1 0]\n",
      " [2 2 1 13 4 1 1 0 0]\n",
      " [2 3 3 1 8 1 1 1 0]\n",
      " [2 2 1 14 8 1 1 0 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 7 1 1 0 1 0]\n",
      " [1 2 1 11 8 1 1 1 0]\n",
      " [2 3 3 13 8 1 1 0 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 9 8 1 1 0 0]\n",
      " [2 2 1 2 1 1 1 0 0]\n",
      " [2 2 1 3 4 1 1 1 0]\n",
      " [2 3 3 4 8 1 0 1 2]\n",
      " [2 2 1 6 3 1 1 1 0]\n",
      " [2 2 1 7 8 1 1 0 0]\n",
      " [2 3 3 3 8 1 1 0 0]\n",
      " [2 2 1 1 8 1 0 0 2]\n",
      " [2 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 6 3 1 1 0 0]\n",
      " [2 2 1 5 8 1 1 0 0]\n",
      " [1 3 3 2 8 1 1 1 0]\n",
      " [1 2 1 1 8 1 1 1 0]\n",
      " [2 2 1 5 9 1 1 1 0]\n",
      " [1 2 1 1 8 1 0 1 0]\n",
      " [1 2 1 1 8 1 0 0 0]\n",
      " [1 2 1 11 8 1 0 1 0]\n",
      " [2 2 1 2 1 1 0 1 0]\n",
      " [2 2 1 9 8 1 0 0 0]\n",
      " [1 3 3 14 8 0 0 0 0]\n",
      " [2 2 1 11 8 1 1 1 0]\n",
      " [2 2 1 3 8 1 0 0 0]\n",
      " [2 2 1 3 8 1 1 0 0]\n",
      " [1 2 1 14 8 1 1 1 0]\n",
      " [2 2 1 14 4 1 1 1 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [1 2 1 7 1 1 1 0 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 7 1 1 0 1 0]\n",
      " [2 2 1 1 8 1 1 0 0]\n",
      " [2 2 1 11 8 1 0 0 2]\n",
      " [2 2 1 14 8 1 1 0 0]\n",
      " [2 3 3 2 8 1 0 0 2]\n",
      " [2 2 1 13 8 1 1 0 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 7 8 1 1 0 0]\n",
      " [2 3 3 2 4 1 1 1 0]\n",
      " [2 2 1 3 4 1 1 1 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 2 1 1 1 0 0]\n",
      " [2 2 1 14 8 1 1 0 0]\n",
      " [2 2 1 5 9 1 1 0 0]\n",
      " [2 2 1 11 4 1 1 1 0]\n",
      " [1 2 1 14 4 1 1 0 0]\n",
      " [2 2 1 14 4 1 1 0 0]\n",
      " [2 2 1 9 8 0 0 0 0]\n",
      " [2 2 1 2 4 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [2 2 1 4 8 0 0 0 0]\n",
      " [1 2 1 7 8 0 0 0 0]\n",
      " [1 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 4 4 0 0 1 0]\n",
      " [1 3 3 6 3 0 0 0 0]\n",
      " [1 2 1 7 7 0 0 0 0]\n",
      " [1 3 3 14 4 0 0 1 0]\n",
      " [2 2 1 6 3 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 0 0]\n",
      " [2 3 3 5 2 0 0 0 0]\n",
      " [1 2 1 4 8 0 0 0 0]\n",
      " [2 2 1 11 8 1 0 1 0]\n",
      " [2 2 1 11 6 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 1]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [2 3 3 10 8 0 0 0 0]\n",
      " [2 3 3 9 8 0 0 0 0]\n",
      " [2 2 1 3 4 0 0 1 2]\n",
      " [2 2 1 4 8 0 0 0 0]\n",
      " [1 2 1 7 4 0 0 0 0]\n",
      " [1 3 3 11 4 0 0 0 0]\n",
      " [2 3 3 6 3 0 0 0 0]\n",
      " [2 2 1 10 8 1 0 0 2]\n",
      " [2 3 3 2 4 0 0 0 0]\n",
      " [2 3 3 3 4 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 2]\n",
      " [1 2 1 11 8 0 1 0 0]\n",
      " [2 2 1 2 8 0 1 0 0]\n",
      " [2 2 1 13 4 0 1 0 0]\n",
      " [1 2 1 6 3 0 1 1 0]\n",
      " [2 2 1 13 8 0 1 0 0]\n",
      " [2 3 3 2 8 0 1 0 0]\n",
      " [1 3 3 8 5 0 0 0 0]\n",
      " [2 2 1 10 8 0 0 1 2]\n",
      " [1 2 1 13 8 0 1 0 0]\n",
      " [2 2 1 13 8 0 1 0 0]\n",
      " [2 2 1 13 8 0 1 0 0]\n",
      " [1 2 1 6 3 0 1 0 0]\n",
      " [1 2 1 6 3 0 1 1 0]\n",
      " [2 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 1 8 0 1 1 0]\n",
      " [2 2 1 1 8 0 1 0 0]\n",
      " [2 2 1 2 8 0 1 1 0]\n",
      " [1 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 4 8 0 0 1 2]\n",
      " [2 2 1 2 8 0 0 1 2]\n",
      " [1 2 1 11 8 0 0 0 0]\n",
      " [1 2 1 11 4 0 0 0 0]\n",
      " [2 3 3 6 3 1 0 1 0]\n",
      " [2 2 1 6 3 0 0 0 0]\n",
      " [2 2 1 6 3 0 0 0 0]\n",
      " [2 2 1 9 4 0 0 1 2]\n",
      " [1 3 3 8 5 0 0 0 0]\n",
      " [1 2 1 13 8 0 0 1 0]\n",
      " [2 3 3 2 8 0 0 1 0]\n",
      " [1 2 1 1 8 0 0 0 0]\n",
      " [1 2 1 4 8 0 0 0 0]\n",
      " [2 3 3 1 8 0 0 0 0]\n",
      " [2 2 1 10 8 1 0 1 2]\n",
      " [2 3 3 2 4 0 0 0 0]\n",
      " [2 1 2 6 7 0 0 1 1]\n",
      " [2 3 3 10 1 0 0 1 2]\n",
      " [2 3 3 2 8 0 0 1 0]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [1 1 2 3 3 0 0 1 2]\n",
      " [1 2 1 3 8 0 0 0 0]\n",
      " [2 3 3 9 8 1 1 0 0]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [1 3 3 14 8 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 7 1 0 0 0 2]\n",
      " [2 3 3 13 8 0 0 0 2]\n",
      " [2 3 3 7 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 0 1]\n",
      " [1 3 3 2 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 4 8 0 0 1 0]\n",
      " [2 2 1 3 1 0 0 0 0]\n",
      " [2 2 1 11 4 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [1 3 3 7 4 0 0 1 0]\n",
      " [1 3 3 1 8 0 0 0 0]\n",
      " [2 2 1 13 8 0 0 1 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [2 2 1 7 1 0 0 1 0]\n",
      " [2 2 1 7 1 0 0 0 0]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [2 2 1 5 9 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [2 3 3 2 1 0 0 0 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 13 8 0 1 1 0]\n",
      " [1 2 1 8 5 0 0 1 0]\n",
      " [2 3 3 6 3 0 0 0 0]\n",
      " [2 3 3 10 8 0 0 1 0]\n",
      " [2 2 1 4 8 0 0 1 2]\n",
      " [2 2 1 7 8 0 0 1 0]\n",
      " [1 2 1 1 8 0 1 1 0]\n",
      " [2 2 1 4 8 0 0 0 0]\n",
      " [1 2 1 11 8 0 0 1 0]\n",
      " [2 2 1 4 8 0 0 1 0]\n",
      " [1 2 1 6 3 0 0 0 0]\n",
      " [1 2 1 9 8 0 0 1 2]\n",
      " [2 2 1 6 3 0 0 1 0]\n",
      " [2 2 1 9 3 0 0 0 0]\n",
      " [2 3 3 9 8 0 0 0 2]\n",
      " [2 2 1 5 2 0 1 0 0]\n",
      " [2 2 1 10 8 0 1 1 0]\n",
      " [1 2 1 1 8 0 0 0 0]\n",
      " [2 3 3 10 8 0 0 0 2]\n",
      " [1 3 3 9 4 0 0 1 0]\n",
      " [2 3 3 12 6 0 0 1 0]\n",
      " [2 3 3 13 8 0 0 1 0]\n",
      " [2 2 1 5 2 0 0 1 0]\n",
      " [1 2 1 9 4 0 0 1 2]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [1 3 3 5 2 0 0 0 0]\n",
      " [2 2 1 4 8 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 1 2]\n",
      " [2 2 1 7 1 0 0 1 0]\n",
      " [2 2 1 7 1 0 0 1 2]\n",
      " [2 2 1 7 1 0 0 1 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [1 3 3 7 1 0 0 0 0]\n",
      " [1 3 3 6 3 0 0 1 0]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [2 3 3 2 8 0 0 1 0]\n",
      " [2 3 3 1 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 1 2]\n",
      " [2 2 1 7 1 0 0 1 0]\n",
      " [2 2 1 10 8 0 0 0 2]\n",
      " [2 2 1 5 8 0 0 0 0]\n",
      " [2 2 1 7 1 0 0 0 0]\n",
      " [2 2 1 1 1 0 0 1 0]\n",
      " [2 2 1 10 8 0 0 1 0]\n",
      " [2 3 3 13 8 0 0 0 0]\n",
      " [1 2 1 4 8 0 0 1 0]\n",
      " [2 3 3 14 4 0 0 0 0]\n",
      " [1 3 3 6 3 0 0 0 0]\n",
      " [2 3 3 9 4 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [2 3 3 8 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 7 1 0 0 1 0]\n",
      " [1 2 1 11 8 0 0 0 2]\n",
      " [2 3 3 7 1 0 0 1 0]\n",
      " [1 2 1 6 3 0 0 0 2]\n",
      " [1 3 3 9 8 0 1 0 0]\n",
      " [1 3 3 2 8 0 1 0 0]\n",
      " [2 2 1 13 8 0 1 0 0]\n",
      " [2 2 1 11 8 0 1 0 0]\n",
      " [2 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 2 8 0 1 0 0]\n",
      " [1 2 1 7 8 0 0 0 0]\n",
      " [2 2 1 7 1 0 0 0 2]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [1 3 3 6 3 0 0 0 0]\n",
      " [2 3 3 9 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 1 0 0]\n",
      " [1 3 3 6 3 0 0 1 0]\n",
      " [2 2 1 7 8 0 0 1 0]\n",
      " [2 2 1 11 8 0 0 0 0]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [2 2 1 3 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 1]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 13 8 0 0 1 0]\n",
      " [2 2 1 5 8 0 0 0 0]\n",
      " [2 2 1 6 3 0 0 0 0]\n",
      " [2 3 3 3 8 0 0 0 0]\n",
      " [2 3 3 6 3 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 1 0]\n",
      " [2 3 3 6 3 0 1 0 0]\n",
      " [2 2 1 6 3 0 1 0 0]\n",
      " [1 2 1 6 3 0 0 1 2]\n",
      " [1 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 9 8 0 1 1 0]\n",
      " [2 2 1 9 8 0 1 0 2]\n",
      " [2 2 1 6 3 0 1 0 0]\n",
      " [2 3 3 10 8 0 0 1 2]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [1 3 3 8 3 0 0 0 0]\n",
      " [1 2 1 6 3 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 6 3 0 0 0 0]\n",
      " [2 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [2 3 3 7 1 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 11 8 0 0 0 0]\n",
      " [2 2 1 13 8 0 0 1 0]\n",
      " [2 2 1 4 8 0 0 1 0]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 1]\n",
      " [2 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 7 1 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 1 0]\n",
      " [1 3 3 2 8 0 0 0 0]\n",
      " [2 2 1 10 8 0 1 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 6 3 0 1 0 0]\n",
      " [1 2 1 8 5 0 1 0 0]\n",
      " [1 2 1 10 8 0 1 1 0]\n",
      " [2 2 1 2 8 0 1 1 0]\n",
      " [1 2 1 13 4 0 1 0 0]\n",
      " [2 2 1 9 8 0 0 0 0]\n",
      " [2 2 1 7 4 0 0 1 0]\n",
      " [1 2 1 9 4 0 0 0 0]\n",
      " [2 3 3 7 4 0 0 0 0]\n",
      " [2 2 1 7 8 0 0 0 0]\n",
      " [2 3 3 7 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 4 8 0 0 1 0]\n",
      " [2 2 1 7 4 0 0 1 0]\n",
      " [2 3 3 7 4 0 0 1 2]\n",
      " [2 2 1 7 8 0 0 0 0]\n",
      " [2 3 3 2 8 0 0 0 2]\n",
      " [1 2 1 7 8 0 1 1 0]\n",
      " [2 3 3 9 8 0 1 1 0]\n",
      " [1 2 1 1 8 0 1 1 0]\n",
      " [2 3 3 2 8 0 1 0 0]\n",
      " [2 2 1 10 8 0 0 0 2]\n",
      " [2 3 3 6 3 0 1 0 0]\n",
      " [2 3 3 9 8 0 0 0 0]\n",
      " [2 3 3 1 8 0 0 1 0]\n",
      " [2 3 3 6 3 0 0 1 0]\n",
      " [2 2 1 11 8 0 0 1 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [2 2 1 11 8 1 1 1 0]\n",
      " [2 2 1 10 8 1 1 0 0]\n",
      " [1 2 1 2 4 1 0 0 0]\n",
      " [1 3 3 2 4 1 0 0 0]\n",
      " [2 2 1 13 8 1 0 0 0]\n",
      " [1 2 1 14 4 1 0 1 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 14 8 1 1 1 0]\n",
      " [2 2 1 3 8 1 1 1 0]\n",
      " [1 2 1 6 3 1 1 0 0]\n",
      " [2 2 1 14 8 1 1 0 0]\n",
      " [1 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [1 2 1 1 8 1 1 0 0]\n",
      " [1 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 2 8 1 1 0 0]\n",
      " [2 3 3 13 8 1 1 1 0]\n",
      " [2 3 3 13 8 1 1 1 0]\n",
      " [1 2 1 8 5 1 0 0 0]\n",
      " [1 2 1 2 8 1 0 0 0]\n",
      " [2 2 1 5 2 1 0 0 0]\n",
      " [2 3 3 2 4 1 0 0 0]\n",
      " [2 2 1 14 8 1 0 0 0]\n",
      " [1 2 1 1 8 1 1 0 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [2 2 1 14 8 1 1 1 0]\n",
      " [2 2 1 9 8 1 1 0 0]\n",
      " [1 2 1 5 2 1 1 1 0]\n",
      " [2 2 1 10 8 1 1 0 0]\n",
      " [1 2 1 11 8 1 1 0 0]\n",
      " [1 2 1 11 8 1 0 1 0]\n",
      " [2 2 1 2 8 1 0 1 0]\n",
      " [2 2 1 9 8 1 0 0 0]\n",
      " [1 2 1 7 1 1 0 1 0]\n",
      " [1 2 1 9 4 1 1 1 0]\n",
      " [2 2 1 11 4 1 1 0 0]\n",
      " [1 2 1 2 4 1 0 1 0]\n",
      " [1 2 1 1 4 1 0 0 0]\n",
      " [2 2 1 7 1 1 0 0 0]\n",
      " [2 2 1 6 3 1 0 0 0]\n",
      " [2 2 1 1 8 1 0 1 0]\n",
      " [1 3 3 6 3 1 0 0 0]\n",
      " [1 2 1 6 3 1 0 0 0]\n",
      " [2 2 1 14 4 1 0 1 0]\n",
      " [2 2 1 13 1 1 0 1 0]\n",
      " [2 2 1 2 8 1 0 0 0]\n",
      " [2 3 3 3 8 1 0 1 0]\n",
      " [2 2 1 7 1 1 0 0 0]\n",
      " [2 3 3 9 4 1 0 1 0]\n",
      " [2 2 1 13 8 1 0 1 0]\n",
      " [2 3 3 7 1 1 1 1 0]\n",
      " [2 3 3 4 8 1 0 0 2]\n",
      " [2 3 3 13 8 1 1 1 0]\n",
      " [2 2 1 4 4 1 1 0 0]\n",
      " [2 2 1 14 8 1 1 1 0]\n",
      " [2 2 1 10 8 1 0 0 2]\n",
      " [2 2 1 5 9 1 1 1 0]\n",
      " [2 2 1 7 1 1 1 0 0]\n",
      " [2 2 1 12 6 1 1 1 0]\n",
      " [2 2 1 13 8 1 1 0 0]\n",
      " [1 3 3 14 4 1 1 0 0]\n",
      " [2 2 1 2 4 1 1 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [1 2 1 13 8 1 1 0 0]\n",
      " [2 2 1 14 4 1 0 0 0]\n",
      " [1 2 1 11 4 1 1 1 0]\n",
      " [1 2 1 3 4 1 1 0 0]\n",
      " [2 2 1 14 4 1 0 0 0]\n",
      " [2 2 1 2 4 1 0 0 0]\n",
      " [2 2 1 11 4 1 0 1 0]\n",
      " [2 2 1 11 4 1 0 1 0]\n",
      " [1 2 1 1 8 1 0 0 0]\n",
      " [2 2 1 13 4 1 1 1 0]\n",
      " [1 2 1 14 4 1 0 0 0]\n",
      " [2 3 3 2 8 1 1 1 0]\n",
      " [1 2 1 1 8 1 1 0 0]\n",
      " [2 2 1 13 8 1 1 1 0]\n",
      " [2 3 3 4 8 1 1 1 0]\n",
      " [2 3 3 14 8 1 1 1 0]\n",
      " [1 2 1 6 3 1 1 1 0]\n",
      " [1 2 1 2 4 1 1 0 0]\n",
      " [2 3 3 2 4 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 2 1 10 8 1 1 1 0]\n",
      " [2 2 1 14 8 1 1 1 0]\n",
      " [2 2 1 5 8 0 1 0 2]\n",
      " [2 2 1 10 8 1 0 1 0]\n",
      " [2 3 3 13 4 1 0 1 0]\n",
      " [1 3 3 5 9 1 0 0 0]\n",
      " [2 2 1 6 3 1 0 1 0]\n",
      " [2 2 1 14 4 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 0 0]\n",
      " [2 3 3 2 8 1 1 1 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [2 2 1 3 8 1 1 0 0]\n",
      " [2 2 1 2 4 1 1 1 0]\n",
      " [2 2 1 2 8 0 0 0 1]\n",
      " [2 2 1 13 8 0 0 1 0]\n",
      " [2 2 1 9 8 1 0 1 0]\n",
      " [2 2 1 2 1 1 0 0 0]\n",
      " [1 2 1 2 8 1 1 1 0]\n",
      " [1 2 1 1 8 1 1 0 0]\n",
      " [2 2 1 11 8 0 1 0 0]\n",
      " [2 2 1 2 8 1 1 1 0]\n",
      " [1 2 1 9 8 1 1 0 0]\n",
      " [2 3 3 2 8 0 0 1 0]\n",
      " [2 3 3 9 8 0 0 0 0]\n",
      " [2 2 1 11 8 0 0 0 0]\n",
      " [2 2 1 2 4 1 0 0 0]\n",
      " [1 3 3 9 8 0 0 1 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [2 3 3 4 8 0 0 1 0]\n",
      " [2 2 1 14 1 0 0 1 0]\n",
      " [2 3 3 9 8 0 0 0 0]\n",
      " [2 3 3 11 4 0 1 1 0]\n",
      " [2 2 1 13 8 0 1 0 0]\n",
      " [2 2 1 2 1 0 1 1 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 2 4 0 1 1 0]\n",
      " [2 2 1 7 8 0 1 1 0]\n",
      " [2 3 3 6 3 0 1 0 0]\n",
      " [2 2 1 10 8 0 1 1 0]\n",
      " [2 3 3 1 8 1 0 0 0]\n",
      " [2 2 1 7 8 0 0 0 0]\n",
      " [2 2 1 2 5 0 0 1 2]\n",
      " [1 2 1 2 8 0 0 0 1]\n",
      " [2 2 1 11 8 0 0 0 0]\n",
      " [2 3 3 3 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 2]\n",
      " [2 3 3 7 1 0 0 1 0]\n",
      " [2 2 1 6 3 0 0 0 0]\n",
      " [2 2 1 4 4 0 0 0 0]\n",
      " [1 2 1 13 8 0 0 0 0]\n",
      " [1 2 1 11 8 0 0 1 0]\n",
      " [1 2 1 10 4 0 1 1 0]\n",
      " [1 2 1 6 3 0 0 0 0]\n",
      " [2 3 3 9 3 0 0 0 0]\n",
      " [1 2 1 13 8 0 1 1 0]\n",
      " [2 2 1 2 6 0 1 1 0]\n",
      " [2 3 3 10 8 0 0 1 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [2 2 1 1 8 0 0 1 0]\n",
      " [2 2 1 9 8 0 0 1 0]\n",
      " [2 2 1 7 1 0 0 1 0]\n",
      " [2 3 3 3 8 0 0 1 0]\n",
      " [2 3 3 1 8 0 0 1 0]\n",
      " [1 2 1 1 4 0 0 0 0]\n",
      " [2 3 3 13 8 0 0 1 0]\n",
      " [2 2 1 3 8 0 0 1 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 1 8 0 0 1 0]\n",
      " [2 2 1 9 4 0 0 1 0]\n",
      " [1 2 1 6 3 0 1 0 0]\n",
      " [2 2 1 7 1 0 0 0 0]\n",
      " [1 2 1 11 8 0 1 1 0]\n",
      " [1 2 1 7 8 0 0 1 2]\n",
      " [2 2 1 7 8 1 0 1 0]\n",
      " [1 2 1 11 8 0 1 1 0]\n",
      " [1 3 3 6 3 0 0 0 0]\n",
      " [2 2 1 2 4 0 1 1 0]\n",
      " [1 2 1 1 8 0 0 0 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 2 8 0 1 1 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [2 2 1 2 8 0 0 0 0]\n",
      " [1 2 1 13 8 0 0 1 0]\n",
      " [2 3 3 3 8 0 0 1 0]\n",
      " [2 3 3 13 8 0 0 0 2]\n",
      " [2 3 3 10 8 0 0 0 0]\n",
      " [1 2 1 2 8 0 0 1 0]\n",
      " [1 2 1 2 8 0 1 1 0]\n",
      " [2 2 1 4 4 0 0 1 2]\n",
      " [2 3 3 6 3 0 0 0 0]\n",
      " [2 2 1 13 8 0 0 0 0]\n",
      " [2 2 1 3 8 0 0 0 0]\n",
      " [1 2 1 1 8 0 0 1 0]\n",
      " [2 3 3 5 4 0 0 0 0]\n",
      " [1 2 1 7 4 0 0 0 0]\n",
      " [1 2 1 1 8 0 0 0 0]\n",
      " [1 2 1 11 4 0 1 1 0]\n",
      " [2 2 1 10 8 0 1 0 0]\n",
      " [1 2 1 6 3 0 0 0 0]\n",
      " [1 2 1 2 8 0 0 0 0]\n",
      " [2 2 1 9 8 0 0 0 0]\n",
      " [2 3 3 4 4 0 0 0 0]\n",
      " [2 2 1 7 8 0 0 1 0]\n",
      " [2 3 3 4 8 0 0 0 0]\n",
      " [2 2 1 10 8 0 0 1 2]\n",
      " [2 3 3 5 4 0 0 0 0]\n",
      " [1 2 1 2 8 0 1 1 0]\n",
      " [1 3 3 6 3 0 1 1 0]\n",
      " [2 2 1 1 8 0 0 0 0]\n",
      " [2 2 1 2 4 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(688, 6)\n"
     ]
    }
   ],
   "source": [
    "X_num = np.copy(credit_data.loc[:,col_num].to_numpy())\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = Imputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)\n",
    "print(np.shape(X_num))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()\n",
    "print(X_cat_bin)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "processed_data = np.column_stack((X_cat_bin,X_num))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0.  ,   1.  ,   0.  , ...,   1.  ,  30.83,   0.  ],\n       [  1.  ,   0.  ,   0.  , ...,   6.  ,  58.67, 560.  ],\n       [  1.  ,   0.  ,   0.  , ...,   0.  ,  24.5 , 824.  ],\n       ...,\n       [  1.  ,   0.  ,   0.  , ...,   1.  ,  25.25,   1.  ],\n       [  0.  ,   1.  ,   0.  , ...,   0.  ,  17.92, 750.  ],\n       [  0.  ,   1.  ,   0.  , ...,   0.  ,  35.  ,   0.  ]])"
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.821 +/- 0.069 roc is: 0.895 +/- 0.019\n",
      "Accuracy for KNN is: 0.740 +/- 0.110 roc is: 0.764 +/- 0.056\n",
      "Accuracy for Bayes is: 0.849 +/- 0.062 roc is: 0.915 +/- 0.038\n",
      "Accuracy for CART is: 0.777 +/- 0.045 roc is: 0.804 +/- 0.035\n",
      "Accuracy for ID30 is: 0.770 +/- 0.054 roc is: 0.794 +/- 0.034\n",
      "Accuracy for MLP is: 0.804 +/- 0.112 roc is: 0.835 +/- 0.094\n",
      "Accuracy for neihgbors is: 0.744 +/- 0.080 roc is: 0.753 +/- 0.056\n",
      "Accuracy for bagging is: 0.851 +/- 0.063 roc is: 0.920 +/- 0.026\n",
      "Accuracy for ADA is: 0.821 +/- 0.068 roc is: 0.916 +/- 0.032\n",
      "Accuracy for RNDForest is: 0.852 +/- 0.065 roc is: 0.931 +/- 0.026\n"
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs, processed_data, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO analyse result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature engeneering et Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                                  1\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will ü b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sms_data = pd.read_csv(\"SMSSpamCollection.data\", sep = '\\t', header = None)\n",
    "print(sms_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "sms_data.replace({'ham':1,'spam':0}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "text_array = sms_data.iloc[:,1].to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words='english', max_features = 500)\n",
    "X_train_counts = count_vect.fit_transform(text_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.930 +/- 0.013 roc is: 0.754 +/- 0.037\n",
      "Accuracy for KNN is: 0.918 +/- 0.014 roc is: 0.919 +/- 0.018\n",
      "Accuracy for Bayes is: nan +/- nan roc is: nan +/- nan\n",
      "Accuracy for CART is: 0.978 +/- 0.007 roc is: 0.928 +/- 0.021\n",
      "Accuracy for ID30 is: 0.976 +/- 0.008 roc is: 0.921 +/- 0.023\n",
      "Accuracy for MLP is: 0.985 +/- 0.003 roc is: 0.978 +/- 0.010\n",
      "Accuracy for neihgbors is: 0.933 +/- 0.013 roc is: 0.909 +/- 0.024\n",
      "Accuracy for bagging is: 0.981 +/- 0.007 roc is: 0.979 +/- 0.005\n",
      "Accuracy for ADA is: 0.976 +/- 0.006 roc is: 0.967 +/- 0.010\n",
      "Accuracy for RNDForest is: 0.897 +/- 0.011 roc is: 0.962 +/- 0.011\n"
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs, X_train_counts, sms_data.iloc[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfid = TfidfTransformer(smooth_idf=False)\n",
    "weigh = tfid.fit_transform(X_train_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [],
   "source": [
    "pipe = Pipeline([('count', CountVectorizer(stop_words='english', max_features = 500)),\n",
    "                 ('tfid', TfidfTransformer(smooth_idf=False))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [],
   "source": [
    "result = pipe.fit_transform(text_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.930 +/- 0.012 roc is: 0.756 +/- 0.031\n",
      "Accuracy for KNN is: 0.916 +/- 0.014 roc is: 0.907 +/- 0.028\n",
      "Accuracy for Bayes is: nan +/- nan roc is: nan +/- nan\n",
      "Accuracy for CART is: 0.979 +/- 0.006 roc is: 0.923 +/- 0.025\n",
      "Accuracy for ID30 is: 0.976 +/- 0.007 roc is: 0.914 +/- 0.025\n",
      "Accuracy for MLP is: 0.985 +/- 0.003 roc is: 0.982 +/- 0.008\n",
      "Accuracy for neihgbors is: 0.936 +/- 0.012 roc is: 0.908 +/- 0.025\n",
      "Accuracy for bagging is: 0.983 +/- 0.006 roc is: 0.980 +/- 0.005\n",
      "Accuracy for ADA is: 0.976 +/- 0.005 roc is: 0.964 +/- 0.008\n",
      "Accuracy for RNDForest is: 0.899 +/- 0.010 roc is: 0.962 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs, result, sms_data.iloc[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pipe = Pipeline([('count', CountVectorizer(stop_words='english', max_features = 500)),\n",
    "                 ('tfid', TfidfTransformer(smooth_idf=False)),\n",
    "                 ('svdt', TruncatedSVD(n_components=143))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for TREE is: 0.967 +/- 0.006 roc is: 0.920 +/- 0.019\n",
      "Accuracy for KNN is: 0.962 +/- 0.007 roc is: 0.963 +/- 0.011\n",
      "Accuracy for Bayes is: 0.977 +/- 0.008 roc is: 0.933 +/- 0.016\n",
      "Accuracy for CART is: 0.975 +/- 0.007 roc is: 0.903 +/- 0.028\n",
      "Accuracy for ID30 is: 0.975 +/- 0.006 roc is: 0.904 +/- 0.026\n",
      "Accuracy for MLP is: 0.984 +/- 0.004 roc is: 0.986 +/- 0.008\n",
      "Accuracy for neihgbors is: 0.966 +/- 0.005 roc is: 0.953 +/- 0.009\n",
      "Accuracy for bagging is: 0.976 +/- 0.008 roc is: 0.970 +/- 0.010\n",
      "Accuracy for ADA is: 0.978 +/- 0.008 roc is: 0.976 +/- 0.011\n",
      "Accuracy for RNDForest is: 0.944 +/- 0.011 roc is: 0.966 +/- 0.014\n"
     ]
    }
   ],
   "source": [
    "result = pipe.fit_transform(text_array)\n",
    "run_classifiers(clfs, result, sms_data.iloc[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Stars                                               Text\n",
      "0          1  Boarded my English Mastiff here over New Year'...\n",
      "1          1  Another case of the Emperor's New Clothes.  So...\n",
      "2          1  Came on Valentine's Day night having pre-bough...\n",
      "3          1  2Nd time eating here today.1st time was great ...\n",
      "4          1  Allegiant is a disaster.  Their fares are chea...\n",
      "...      ...                                                ...\n",
      "47366      5  This is our favorite coffee place in Montreal!...\n",
      "47367      5  Had to visit the Carlos bakery and went on a s...\n",
      "47368      5  Some of the best Tom Yum we've ever had. Also ...\n",
      "47369      5  This is the best groomer in the valley, she is...\n",
      "47370      5  I agree with the other reviewers: this is a gr...\n",
      "\n",
      "[47371 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"yelp-text-by-stars.csv\", sep =';')\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "outputs": [],
   "source": [
    "text = data.iloc[:,1]\n",
    "result = pipe.fit_transform(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-422-e1216b49e4cb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mrun_classifiers\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclfs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-97-f493355d547f>\u001B[0m in \u001B[0;36mrun_classifiers\u001B[1;34m(_clfs, _X, _y)\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_clfs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m         \u001B[0mcv_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_val_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m\"precision\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m         \u001B[0mauc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_val_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_X\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_y\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;34m'roc_auc'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Accuracy for {0} is: {1:.3f} +/- {2:.3f} roc is: {3:.3f} +/- {4:.3f}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcv_acc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mauc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mauc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    438\u001B[0m     \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_scorer\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mMake\u001B[0m \u001B[0ma\u001B[0m \u001B[0mscorer\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0ma\u001B[0m \u001B[0mperformance\u001B[0m \u001B[0mmetric\u001B[0m \u001B[1;32mor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    439\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 440\u001B[1;33m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    441\u001B[0m     \"\"\"\n\u001B[0;32m    442\u001B[0m     \u001B[1;31m# To ensure multimetric format is not supported\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[0mscorers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_multimetric_scoring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 246\u001B[1;33m     \u001B[1;31m# We clone the estimator to make sure that all the folds are\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    247\u001B[0m     \u001B[1;31m# independent, and that it is pickle-able.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    248\u001B[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1044\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1045\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_safe_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    594\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0my_train\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    896\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    897\u001B[0m         \u001B[0mReturns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 898\u001B[1;33m         \u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    899\u001B[0m         \u001B[0mself\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mDecisionTreeClassifier\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    900\u001B[0m             \u001B[0mFitted\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    387\u001B[0m                                            \u001B[0mmin_samples_leaf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m                                            \u001B[0mmin_weight_leaf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 389\u001B[1;33m                                            \u001B[0mmax_depth\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    390\u001B[0m                                            \u001B[0mmax_leaf_nodes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m                                            \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmin_impurity_decrease\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "run_classifiers(clfs, result, data.iloc[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}